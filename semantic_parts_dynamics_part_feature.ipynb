{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "from collections import Counter\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from svgpathtools import parse_path\n",
    "import svgpathtools\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "from svgpathtools import parse_path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "features_dir= os.path.join(results_dir,'features')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)  \n",
    "\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)  \n",
    "\n",
    "if not os.path.exists(features_dir):\n",
    "    os.makedirs(features_dir)\n",
    "    \n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis'))        \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper dictionaries \n",
    "OBJECT_TO_CATEGORY = {\n",
    "    'basset': 'dog', 'beetle': 'car', 'bloodhound': 'dog', 'bluejay': 'bird',\n",
    "    'bluesedan': 'car', 'bluesport': 'car', 'brown': 'car', 'bullmastiff': 'dog',\n",
    "    'chihuahua': 'dog', 'crow': 'bird', 'cuckoo': 'bird', 'doberman': 'dog',\n",
    "    'goldenretriever': 'dog', 'hatchback': 'car', 'inlay': 'chair', 'knob': 'chair',\n",
    "    'leather': 'chair', 'nightingale': 'bird', 'pigeon': 'bird', 'pug': 'dog',\n",
    "    'redantique': 'car', 'redsport': 'car', 'robin': 'bird', 'sling': 'chair',\n",
    "    'sparrow': 'bird', 'squat': 'chair', 'straight': 'chair', 'tomtit': 'bird',\n",
    "    'waiting': 'chair', 'weimaraner': 'dog', 'white': 'car', 'woven': 'chair',\n",
    "}\n",
    "CATEGORY_TO_OBJECT = {\n",
    "    'dog': ['basset', 'bloodhound', 'bullmastiff', 'chihuahua', 'doberman', 'goldenretriever', 'pug', 'weimaraner'],\n",
    "    'car': ['beetle', 'bluesedan', 'bluesport', 'brown', 'hatchback', 'redantique', 'redsport', 'white'],\n",
    "    'bird': ['bluejay', 'crow', 'cuckoo', 'nightingale', 'pigeon', 'robin', 'sparrow', 'tomtit'],\n",
    "    'chair': ['inlay', 'knob', 'leather', 'sling', 'squat', 'straight', 'waiting', 'woven'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##helpers\n",
    "\n",
    "def cleanup_df(X):\n",
    "    if 'Unnamed: 0' in X.columns:\n",
    "        X = X.drop(columns=['Unnamed: 0'])\n",
    "    return X\n",
    "\n",
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]\n",
    "\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "def entropy(probs):    \n",
    "    return - 1 * sum(map(lambda x: x * np.log(x),probs))\n",
    "\n",
    "def KL_div_uniform(probs):\n",
    "    unif_p = 1/len(probs)\n",
    "    return sum(map(lambda x: unif_p * np.log(unif_p/x),probs))\n",
    "\n",
    "def softmax(X):\n",
    "    '''\n",
    "    input: X is a (1 x N) array\n",
    "    output: 1 x N array\n",
    "    '''\n",
    "    return np.exp(X)/np.sum(np.exp(X))\n",
    "\n",
    "def minmaxscale(X):\n",
    "\n",
    "    return (X-np.min(X))/(np.max(X)-np.min(X))\n",
    "\n",
    "def calculate_CI(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), stats.sem(a)\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m.round(3), (m-h).round(3), (m+h).round(3)\n",
    "\n",
    "def get_ordered_objs_list_by_category(F):\n",
    "    objs_list = []\n",
    "    close_inds = F['condition'] == 'closer'\n",
    "    far_inds = F['condition'] == 'further'\n",
    "    categories = ['bird','car','chair','dog']\n",
    "    for this_category in categories:\n",
    "        category_inds = F['category'] == this_category\n",
    "        objs_list.append(list(F[(category_inds) & (far_inds)].reset_index(drop=True).target.values))\n",
    "    return flatten(objs_list)\n",
    "\n",
    "\n",
    "def aggregate_sketches(F,OBJECT_TO_CATEGORY=OBJECT_TO_CATEGORY):\n",
    "    '''\n",
    "    F is full num sketches x num features matrix\n",
    "    OBJECT_TO_CATEGORY is a dictionary that maps from object to category\n",
    "    '''\n",
    "    ## aggregate by target and condition and take the mean across rows within each group\n",
    "    F2 = F.groupby(['target','condition']).mean().reset_index()\n",
    "\n",
    "    ## re-add category back to the F dataframe so we can subset on that later \n",
    "    ##( taking mean above removes it b/c it is a string)\n",
    "    F2['category'] = F2['target'].apply(lambda x: OBJECT_TO_CATEGORY[x])    \n",
    "    \n",
    "    return F2\n",
    "\n",
    "def resample_sketches(F0,\n",
    "                      groupby=['target','condition'],\n",
    "                      random_state=0):    \n",
    "    Fboot = F0.groupby(groupby).apply(lambda x: x.sample(n=len(x), replace=True, random_state=random_state))\n",
    "    cols = Fboot.columns\n",
    "    Fboot = Fboot.xs(cols, axis=1, drop_level=True).reset_index(drop=True)\n",
    "    return Fboot\n",
    "\n",
    "def get_context_difference_mat(F2):\n",
    "    to_inspect = 'category'\n",
    "    categories = ['bird','car','chair','dog']\n",
    "    d = []\n",
    "    for i, this_category in enumerate(categories):\n",
    "        c,f, obj_listc, obj_listf = subset_dataframe_by_condition(F2,\n",
    "                                            to_inspect=to_inspect,\n",
    "                                            this_category=this_category) ## get subset of features\n",
    "\n",
    "        _d = c.sub(f)\n",
    "        if len(d)==0:\n",
    "            d = _d\n",
    "        else:\n",
    "            d = pd.concat((d,_d),axis=0) \n",
    "    return d\n",
    "\n",
    "def get_sparsity(vec):\n",
    "    '''\n",
    "    see: https://math.stackexchange.com/questions/117860/how-to-define-sparseness-of-a-vector\n",
    "    maximally sparse = 1\n",
    "    minimally sparse = 0\n",
    "    '''\n",
    "    k = len(vec)\n",
    "    L1norm = np.linalg.norm(vec,ord=1)\n",
    "    L2norm = np.linalg.norm(vec,ord=2)\n",
    "    s = (np.sqrt(k) - (L1norm/L2norm))/(np.sqrt(k) - 1)\n",
    "    return s\n",
    "\n",
    "def subset_dataframe_by_condition(F,to_inspect='all',this_category='bird',this_object='bluejay'):\n",
    "    '''\n",
    "    input: F: dataframe (num_sketches x num_features)\n",
    "           to_inspect: a string indicating whether to subset by ['object','category','all']\n",
    "           this_category: IF to_inspect == 'category', then we define this to subset by that category only\n",
    "           this_object: IF to_inspect == 'object', then we define this to subset by that object only\n",
    "           \n",
    "    returns: two feature matrices, c and f, corresponding to the close and far subsetted feature matrices\n",
    "           \n",
    "    '''\n",
    "        \n",
    "    F = F.sort_values(by=['category','target'])\n",
    "\n",
    "    ## get context condition inds for subsetting dataframe\n",
    "    close_inds = F['condition'] == 'closer'\n",
    "    far_inds = F['condition'] == 'further'\n",
    "\n",
    "    ## if we want to inspect particular category\n",
    "    category_inds = F['category']==this_category\n",
    "\n",
    "    ## if we want to inspect particular object\n",
    "    obj_list = np.unique(F.target.values)\n",
    "    obj_inds = F['target']==this_object  \n",
    "    \n",
    "    ## get names of columns that contain stroke-count & arclength information\n",
    "    numstrokes_cols = [i for i in F.columns if i.split('_')[-1]=='numstrokes']\n",
    "    arclength_cols = [i for i in F.columns if i.split('_')[-1]=='arclength']\n",
    "    feat_cols = numstrokes_cols + arclength_cols\n",
    "    \n",
    "    if to_inspect == 'object':    \n",
    "        ## extract particular row corresponding to this OBJECT in each condition\n",
    "        f = F[(far_inds) & obj_inds][feat_cols].reset_index(drop=True)\n",
    "        c = F[(close_inds) & obj_inds][feat_cols].reset_index(drop=True)\n",
    "        obj_listf = F[(far_inds) & obj_inds]['target'].values\n",
    "        obj_listc = F[(close_inds) & obj_inds]['target'].values\n",
    "    elif to_inspect == 'category':\n",
    "        ## extract particular rows corresponding to this CATEGORY in each condition\n",
    "        f = F[(category_inds) & (far_inds)][feat_cols].reset_index(drop=True)\n",
    "        c = F[(category_inds) & (close_inds)][feat_cols].reset_index(drop=True)\n",
    "        obj_listf = F[(category_inds) & (far_inds)]['target'].values\n",
    "        obj_listc = F[(category_inds) & (close_inds)]['target'].values\n",
    "    elif to_inspect == 'all':\n",
    "        ## extract particular rows corresponding to each condition\n",
    "        f = F[far_inds][feat_cols].reset_index(drop=True)\n",
    "        c = F[close_inds][feat_cols].reset_index(drop=True) \n",
    "        obj_listf = F[far_inds]['target'].values\n",
    "        obj_listc = F[close_inds]['target'].values\n",
    "        \n",
    "    return c, f, obj_listc, obj_listf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in annotated sketch dataset| subsetted for sketches with 3 annotations\n",
    "D=cleanup_df(pd.read_pickle(os.path.join(csv_dir, 'semantic_parts_annotated_data_pckl')))\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating spline and stroke level dataframes for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the list of unique labels applied to sketches\n",
    "unique_labels = np.unique(D.label.values)\n",
    "\n",
    "## Removing Nones and obviously wrong super long lables\n",
    "unique_labels = [i for i in unique_labels if i is not None]\n",
    "unique_labels = [i for i in unique_labels if len(i)<900]\n",
    "\n",
    "print 'we have {} unique labels'.format(len(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cats= np.unique(D['category'])\n",
    "##Create empty dictionary with categories as keys. We will use this to store part occurrence data for our categories\n",
    "label_vect_dict = {unique_cats[0]:None,unique_cats[1]:None,unique_cats[2]:None,unique_cats[3]:None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create vectors that contain the number of part instances in each sketch\n",
    "num_annots=3\n",
    "\n",
    "for category in unique_cats:\n",
    "    DS= D[D['category']==category]\n",
    "    unique_sketches_in_cat = np.unique(DS['sketch_id'])\n",
    "    unique_labels_in_cat = np.unique(DS['label'])\n",
    "    ## initialize matrix that has the correct dimensions\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)), dtype=int)\n",
    "    unique_labels_in_cat= np.array(unique_labels_in_cat)\n",
    "    for s,this_sketch in enumerate(unique_sketches_in_cat):\n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSS = DS[DS['sketch_id']==this_sketch]\n",
    "        annotation_ids = np.unique(DSS['annotation_id'].values)    \n",
    "        for this_annotation in annotation_ids:\n",
    "            DSA = DSS[DSS['annotation_id']==this_annotation]\n",
    "            label_list = DSA.label.values\n",
    "            for this_label in label_list:\n",
    "                label_ind = unique_labels_in_cat==this_label\n",
    "                label_vec[label_ind] += 1\n",
    "            \n",
    "        Label_Vec[s,:]=label_vec/num_annots\n",
    "    label_vect_dict[category]= Label_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels=[]\n",
    "valid_labels_dict={}\n",
    "for category in unique_cats:\n",
    "    vect = label_vect_dict[category]\n",
    "    thresh = 50\n",
    "    #print 'These are the labels that appear at least {} times:'.format(thresh)\n",
    "    #print unique_labels[np.sum(Label_Vec,0)>thresh]\n",
    "    unique_labels_in_cat = np.unique(D[D['category']==category]['label'])\n",
    "    plot_labels= unique_labels_in_cat[np.sum(vect,0)>thresh]\n",
    "    valid_labels_dict[category]=plot_labels\n",
    "    valid_labels.append(plot_labels)\n",
    "\n",
    "\n",
    "    prop_labels=[]\n",
    "    for part in plot_labels:\n",
    "        DS=D[D['category']==category]\n",
    "        prop_labels.append(DS[DS['label']==part]['annotation_id'].nunique()/DS['annotation_id'].nunique())\n",
    "    \n",
    "    \n",
    "#     sns.set_context('talk')\n",
    "#     plt.figure(figsize=(12,7))\n",
    "#     plt.ylim(0,1)\n",
    "#     h = plt.bar(plot_labels,prop_labels)\n",
    "#     plt.title('Proportion of {} annotations with labels'.format(category))\n",
    "#     plt.ylabel('proportion of annotations')\n",
    "#     plt.xlabel('Part')\n",
    "    \n",
    "##flattening valid labels\n",
    "valid_labels = [item for sublist in valid_labels for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a spline-level df where the modal label is set as the 'true' label for any given spline\n",
    "spline_df= D.groupby('spline_id').agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "spline_df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a stroke-level dataframe that takes the mode value of annotation for its children splines to set as its\n",
    "##label value\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "stroke_svgs=OrderedDict()\n",
    "for category in unique_cats:\n",
    "    DS=D[D['category']==category]\n",
    "    for sketch in np.unique(DS['sketch_id']):\n",
    "        DSS=DS[DS['sketch_id']==sketch]\n",
    "        for stroke in np.unique(DSS['stroke_num']):\n",
    "            DSA=DSS[DSS['stroke_num']==stroke]\n",
    "            DSA=DSA.reset_index()\n",
    "            stroke_svgs[DSA['stroke_id'][0]] = DSA['sketch_svg_string'][0][stroke]\n",
    "\n",
    "            \n",
    "            \n",
    "stroke_svg_df= pd.DataFrame.from_dict(stroke_svgs, orient='index')    \n",
    "stroke_group_data= D.groupby('stroke_id').agg(lambda x: Counter(x).most_common(1)[0][0])\n",
    "labels= pd.DataFrame(stroke_group_data[['sketch_id','label','stroke_num','condition','target','category','outcome']])\n",
    "stroke_df=pd.merge(stroke_svg_df,labels,left_index=True, right_index =True)\n",
    "stroke_df.reset_index(level=0, inplace=True)\n",
    "stroke_df=stroke_df.rename(index=str, columns={\"index\": \"stroke_id\", 0: \"svg\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding total arclength information to stroke dataframe\n",
    "\n",
    "def calculate_arclength(svg):\n",
    "    try:\n",
    "        arclength= parse_path(svg).length()\n",
    "    except ZeroDivisionError:\n",
    "        print 'zero div error'\n",
    "        arclength = 0\n",
    "    return arclength\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_df['arc_length'] = stroke_df['svg'].apply(calculate_arclength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_df[stroke_df['condition']=='closer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.annotation_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-annotator reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the number of unique labels assigned to a given spline across annotations\n",
    "a=[]\n",
    "num_diff_annots = []\n",
    "for this_cat in unique_cats:\n",
    "    DS=D[D['category']==this_cat]\n",
    "    labels = valid_labels_dict[this_cat]\n",
    "    unique_sketches_in_cat=np.unique(DS['sketch_id'])\n",
    "    \n",
    "\n",
    "   \n",
    "    for this_sketch_id in unique_sketches_in_cat:\n",
    "        DSA=DS[DS['sketch_id']==this_sketch_id]\n",
    "        unique_splines = np.unique(DSA['cumulative_spline_num'])\n",
    "        for i,this_spline in enumerate(unique_splines):\n",
    "            DSB =DSA[DSA['cumulative_spline_num']==this_spline]\n",
    "            numannots= 4-len(np.unique(DSB['label']))\n",
    "            if len(np.unique(DSB['label'])) == 3:\n",
    "                a.append(this_sketch_id)\n",
    "            if numannots==0:\n",
    "                numannots=1\n",
    "            num_diff_annots.append(numannots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting variability in spline annots\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(num_diff_annots, bins= range(1,5), align='left', density='True')\n",
    "plt.title('Inter-annotator reliability')\n",
    "plt.ylabel('proportion of splines')\n",
    "plt.xlabel('Annotator agreement on label')\n",
    "plt.xticks([1,2,3],['0/3','2/3','3/3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke-part relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spline_dfs = spline_df\n",
    "stroke_dfs = stroke_df\n",
    "spline_annots_per_stroke = []\n",
    "for this_cat in unique_cats:\n",
    "    labels = valid_labels_dict[this_cat]\n",
    "    DS=spline_dfs[spline_dfs['category']==this_cat]\n",
    "    unique_sketches_in_cat= np.unique(DS['sketch_id'])\n",
    "    for this_sketch_id in unique_sketches_in_cat:\n",
    "        DSA=DS[DS['sketch_id']==this_sketch_id]\n",
    "        unique_strokes = np.unique(DSA['stroke_num'])\n",
    "        for i,this_stroke in enumerate(unique_strokes):\n",
    "            DSB =DSA[DSA['stroke_num']==this_stroke]\n",
    "            numlabels= DSB['label'].nunique()\n",
    "            spline_annots_per_stroke.append(numlabels)\n",
    "h= plt.hist(spline_annots_per_stroke, bins =[1,2,3,4,5,6], align='left', density=\"True\", color='grey')\n",
    "pps_series = pd.Series(np.array([h[0][0],h[0][1],h[0][2:].sum()]), index=['1', '2', '3+'], \\\n",
    "                     )\n",
    "\n",
    "strokes_per_part = []\n",
    "for this_cat in unique_cats:\n",
    "    DS=stroke_dfs[stroke_dfs['category']==this_cat]\n",
    "    unique_sketches_in_cat= np.unique(DS['sketch_id'])\n",
    "    for this_sketch_id in unique_sketches_in_cat:\n",
    "        DSA=DS[DS['sketch_id']==this_sketch_id]\n",
    "        parts_in_sketch = np.unique(DSA['label'])\n",
    "        for i,this_part in enumerate(parts_in_sketch):\n",
    "            DSB =DSA[DSA['label']==this_part]\n",
    "            numstrokes= DSB['stroke_num'].nunique()\n",
    "            strokes_per_part.append(numstrokes)\n",
    "h= plt.hist(strokes_per_part, bins =[1,2,3,4,5,6,7,8,9,10], align='left', density=\"True\", color ='grey')\n",
    "spp_series = pd.Series(np.array([h[0][0],h[0][1],h[0][2:].sum()]), index=['1', '2', '3+'], \\\n",
    "                     )\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,15))\n",
    "colors = sns.color_palette('tab20c')\n",
    "\n",
    "ax1 = fig.add_subplot(212) # Create matplotlib axes\n",
    "ax2 = fig.add_subplot(211)\n",
    "\n",
    "\n",
    "# pd.DataFrame(spp_series).T.plot(ax=axes[0,1]).bar(stacked=True,legend=False, width =0.2)\n",
    "# pd.DataFrame(pps_series).T.plot(ax=axes[0,0]).bar(stacked=True,legend=False, width =0.2)\n",
    "\n",
    "\n",
    "b1=pd.DataFrame(spp_series).T.plot.barh(stacked=True,legend=False, width =0.25,ax=ax1, color=[colors[0],colors[1],colors[2]])\n",
    "b2=pd.DataFrame(pps_series).T.plot.barh(stacked=True,legend=False, width =0.25,ax=ax2, color=[colors[4],colors[5],colors[6]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for item in b1.get_xticklabels():\n",
    "     item.set_rotation(0)\n",
    "\n",
    "for item in b2.get_xticklabels():\n",
    "     item.set_rotation(0)\n",
    "\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "ax1.set_ylabel('')\n",
    "ax2.set_ylabel('')\n",
    "ax1.set_xlabel('',labelpad = 15)\n",
    "ax2.set_xlabel('',labelpad= 15)\n",
    "ax1.set_yticks([])\n",
    "ax2.set_yticks([])\n",
    "plt.subplots_adjust(wspace=1)\n",
    "\n",
    "\n",
    "\n",
    "#plt.savefig(os.path.join(plot_dir,'stroke_part_relationship'),edgecolor='w',bbox_inches='tight',dpi=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "iters=5\n",
    "c_pps=[]\n",
    "f_pps=[]\n",
    "c_spp=[]\n",
    "f_spp=[]\n",
    "for this_cond in np.unique(D.condition):\n",
    "    for i in range(iters):\n",
    "        spline_dfs = spline_df[spline_df['condition']==this_cond]\n",
    "        stroke_dfs = stroke_df[stroke_df['condition']==this_cond]\n",
    "        spline_annots_per_stroke = []\n",
    "\n",
    "\n",
    "        unique_sketches_in_cond= np.unique(spline_dfs['sketch_id'])\n",
    "        sample_sketches = np.random.choice(unique_sketches_in_cond,len(unique_sketches_in_cond),replace=True)\n",
    "        for this_sketch_id in sample_sketches:\n",
    "            DSA=spline_dfs[spline_dfs['sketch_id']==this_sketch_id]\n",
    "            unique_strokes = np.unique(DSA['stroke_num'])\n",
    "            for i,this_stroke in enumerate(unique_strokes):\n",
    "                DSB =DSA[DSA['stroke_num']==this_stroke]\n",
    "                numlabels= DSB['label'].nunique()\n",
    "                spline_annots_per_stroke.append(numlabels)\n",
    "\n",
    "        h= np.array(Counter(spline_annots_per_stroke).values())    \n",
    "        pps_series = np.array([h[0],h[1],h[2:].sum()])\n",
    "        if this_cond=='closer':\n",
    "            c_pps.append(pps_series)\n",
    "        elif this_cond == 'further':\n",
    "            f_pps.append(pps_series)\n",
    "\n",
    "\n",
    "\n",
    "        strokes_per_part = []\n",
    "\n",
    "        unique_sketches_in_cond= np.unique(stroke_dfs['sketch_id'])\n",
    "        sample_sketches = np.random.choice(unique_sketches_in_cond,len(unique_sketches_in_cond),replace=True)\n",
    "        for this_sketch_id in sample_sketches:\n",
    "            DSA=stroke_dfs[stroke_dfs['sketch_id']==this_sketch_id]\n",
    "            parts_in_sketch = np.unique(DSA['label'])\n",
    "            for i,this_part in enumerate(parts_in_sketch):\n",
    "                DSB =DSA[DSA['label']==this_part]\n",
    "                numstrokes= DSB['stroke_num'].nunique()\n",
    "                strokes_per_part.append(numstrokes)\n",
    "        h= np.array(Counter(strokes_per_part).values())    \n",
    "        spp_series = np.array([h[0],h[1],h[2:].sum()])\n",
    "        if this_cond=='closer':\n",
    "            c_spp.append(spp_series)\n",
    "        elif this_cond == 'further':\n",
    "            f_spp.append(spp_series)\n",
    "\n",
    "c_pps=np.vstack(c_pps)\n",
    "\n",
    "f_pps=np.vstack(f_pps)\n",
    "\n",
    "c_spp=np.vstack(c_spp)\n",
    "\n",
    "f_spp=np.vstack(f_spp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_pps= np.load(os.path.join(features_dir,'c_pps.npy'))\n",
    "c_pps = c_pps/c_pps.sum(axis=1)[:,None]\n",
    "# c_spp= np.load(os.path.join(features_dir,'c_spp.npy'))\n",
    "c_spp = c_spp/c_spp.sum(axis=1)[:,None]\n",
    "# f_pps= np.load(os.path.join(features_dir,'f_pps.npy'))\n",
    "f_pps = f_pps/f_pps.sum(axis=1)[:,None]\n",
    "# f_spp= np.load(os.path.join(features_dir,'f_spp.npy'))\n",
    "f_spp = f_spp/f_spp.sum(axis=1)[:,None]\n",
    "\n",
    "\n",
    "c_pps[:,1]=c_pps[:,1]+c_pps[:,2]\n",
    "c_pps=np.delete(c_pps,2,1)\n",
    "f_pps[:,1]=f_pps[:,1]+f_pps[:,2]\n",
    "f_pps=np.delete(f_pps,2,1)\n",
    "\n",
    "\n",
    "\n",
    "c_spp[:,1]=c_spp[:,1]+c_spp[:,2]\n",
    "c_spp=np.delete(c_spp,2,1)\n",
    "f_spp[:,1]=f_spp[:,1]+f_spp[:,2]\n",
    "f_spp=np.delete(f_spp,2,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parts per stroke\n",
    "\n",
    "c_pps_CI = np.percentile(c_pps[:,1],2.5).round(3),np.percentile(c_pps[:,1],97.5).round(3)\n",
    "f_pps_CI = np.percentile(f_pps[:,1],2.5).round(3),np.percentile(f_pps[:,1],97.5).round(3)\n",
    "print c_pps_CI, f_pps_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strokes per part\n",
    "\n",
    "c_spp_CI = np.percentile(c_spp[:,1],2.5).round(3),np.percentile(c_spp[:,1],97.5).round(3)\n",
    "f_spp_CI = np.percentile(f_spp[:,1],2.5).round(3),np.percentile(f_spp[:,1],97.5).round(3)\n",
    "print c_spp_CI, f_spp_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-streak analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'normalized'\n",
    "##Creating a dictionary of sketch_id with associated part sequences\n",
    "seq_dict={}\n",
    "for this_sketch in np.unique(stroke_df['sketch_id']):\n",
    "    parts_list=[]\n",
    "    DS=stroke_df[stroke_df['sketch_id']==this_sketch]\n",
    "    for i, row in DS.iterrows():\n",
    "        parts_list.append(stroke_df['label'][i])\n",
    "    seq_dict[this_sketch]=parts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for getting 'mean streak_length' from a particular sketch for ground truth and scrambled part orders\n",
    "\n",
    "import random\n",
    "\n",
    "def get_mean_streak(sketch_id):\n",
    "    parts = seq_dict[sketch_id]\n",
    "    streak_counter=1\n",
    "    list_of_streaks=[]\n",
    "    for obj in range(len(parts)-1):\n",
    "        if parts[obj]==parts[obj+1]:\n",
    "            streak_counter+=1\n",
    "        else:\n",
    "            list_of_streaks.append(streak_counter)\n",
    "            streak_counter=1 \n",
    "    list_of_streaks.append(streak_counter)\n",
    "    return np.mean(list_of_streaks)\n",
    "\n",
    "def get_scramble_mean_streak(sketch_id):\n",
    "    parts = seq_dict[sketch_id]\n",
    "    scram_parts=random.sample(parts,len(parts))\n",
    "    streak_counter=1\n",
    "    list_of_streaks=[]\n",
    "    for obj in range(len(scram_parts)-1):\n",
    "        if scram_parts[obj]==scram_parts[obj+1]:\n",
    "            streak_counter+=1\n",
    "        else:\n",
    "            list_of_streaks.append(streak_counter)\n",
    "            streak_counter=1 \n",
    "    list_of_streaks.append(streak_counter)\n",
    "    return np.mean(list_of_streaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over all sketches to get mean streakiness for each sketch_id\n",
    "\n",
    "gt_streak_mean={}\n",
    "for this_cat in unique_cats:\n",
    "    DS= stroke_df[stroke_df['category']==this_cat]\n",
    "    streak_mean_list=[]\n",
    "    for this_sketch in np.unique(DS['sketch_id']):\n",
    "        streak_mean_list.append(get_mean_streak(this_sketch))\n",
    "    gt_streak_mean[this_cat]=np.mean(streak_mean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of exception sketches\n",
    "single_stroke_sketches=[]\n",
    "single_label_sketches=[]\n",
    "strokes_equal_labels_sketches=[]\n",
    "for this_sketch in stroke_df.sketch_id.unique():\n",
    "    stroke_df_s= stroke_df[stroke_df['sketch_id']==this_sketch]\n",
    "    if stroke_df_s.stroke_num.nunique()==1:\n",
    "        single_stroke_sketches.append(this_sketch)\n",
    "    if stroke_df_s.label.nunique()==1:\n",
    "        single_label_sketches.append(this_sketch)\n",
    "    if stroke_df_s.label.nunique()== stroke_df_s.stroke_num.nunique():\n",
    "        strokes_equal_labels_sketches.append(this_sketch)\n",
    "ss_sketches_labels={}\n",
    "sl_sketches_numstrokes={}\n",
    "sel_sketches_labels={}\n",
    "for this_sketch in single_stroke_sketches:\n",
    "    ss_sketches_labels[this_sketch] = stroke_df[stroke_df['sketch_id']==this_sketch].label\n",
    "for this_sketch in single_label_sketches:\n",
    "    sl_sketches_numstrokes[this_sketch]=stroke_df[stroke_df['sketch_id']==this_sketch].stroke_num.nunique()\n",
    "for this_sketch in strokes_equal_labels_sketches:\n",
    "    sel_sketches_labels[this_sketch]=stroke_df[stroke_df['sketch_id']==this_sketch].label.unique()\n",
    "\n",
    "    \n",
    "_donotpermute=single_stroke_sketches + single_label_sketches + strokes_equal_labels_sketches\n",
    "donotpermute=np.unique(_donotpermute).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##z-score of gt\n",
    "#scrambled_higher_prop={}\n",
    "gt_streak_zscore={}\n",
    "true_streak_means = {}\n",
    "permuted_streak_means = {}\n",
    "for this_target in stroke_df.target.unique():\n",
    "    DA=stroke_df[stroke_df['target']==this_target]\n",
    "    for this_sketch in DA.sketch_id.unique():\n",
    "        if this_sketch not in donotpermute:\n",
    "            prop_counter=0\n",
    "            intact_mean_streak = get_mean_streak(this_sketch)\n",
    "            permuted_streak_list = []\n",
    "            for i in range(1000):\n",
    "                scrambled_mean_streak=get_scramble_mean_streak(this_sketch)\n",
    "                permuted_streak_list.append(scrambled_mean_streak)\n",
    "#                 if intact_mean_streak<scrambled_mean_streak:\n",
    "#                     prop_counter+=1\n",
    "            try:  \n",
    "                assert np.isnan((get_mean_streak(this_sketch)-np.mean(permuted_streak_list))/np.std(permuted_streak_list)) == False\n",
    "                true_streak_means[this_sketch] = get_mean_streak(this_sketch)\n",
    "                permuted_streak_means[this_sketch] = np.mean(permuted_streak_list)\n",
    "                gt_streak_zscore[this_sketch]=(get_mean_streak(this_sketch)-np.mean(permuted_streak_list))/np.std(permuted_streak_list)\n",
    "            except AssertionError:\n",
    "                print stroke_df[stroke_df.sketch_id==this_sketch].stroke_num.nunique(),stroke_df[stroke_df.sketch_id==this_sketch].label.nunique()\n",
    "#             scrambled_higher_prop[this_sketch]=prop_counter/1000\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls=[]\n",
    "objs=[]\n",
    "cond=[]\n",
    "cat=[]\n",
    "for this_target in stroke_df.target.unique():\n",
    "    DA=stroke_df[stroke_df['target']==this_target]\n",
    "    _sketch_ids = DA.sketch_id.unique()\n",
    "    _sketch_ids = [x for x in _sketch_ids if x not in donotpermute]\n",
    "    true_streaks_sub=dict((k, true_streak_means[k]) for k in _sketch_ids)\n",
    "    perm_streaks_sub = dict((k, permuted_streak_means[k]) for k in _sketch_ids)\n",
    "    tls.append(true_streaks_sub.values())\n",
    "    cond.append([\"Intact\"]*len(true_streaks_sub.values()))\n",
    "    objs.append([this_target]*len(true_streaks_sub.values()))\n",
    "    cat.append([OBJECT_TO_CATEGORY[this_target]]*len(true_streaks_sub.values()))\n",
    "    \n",
    "    tls.append(perm_streaks_sub.values())\n",
    "    cond.append([\"Scrambled\"]*len(true_streaks_sub.values()))\n",
    "    objs.append([this_target]*len(true_streaks_sub.values()))\n",
    "    cat.append([OBJECT_TO_CATEGORY[this_target]]*len(true_streaks_sub.values()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = [item for sublist in tls for item in sublist]\n",
    "objs= [item for sublist in objs for item in sublist]\n",
    "cond= [item for sublist in cond for item in sublist]\n",
    "cat= [item for sublist in cat for item in sublist]\n",
    "assert len(tls)==len(objs)==len(cond)==len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data= { 'objects':objs,'Mean Streak Length':tls, \"Condition\":cond, \"category\":cat}\n",
    "data= pd.DataFrame(data = _data)\n",
    "\n",
    "colors = sns.color_palette(\"husl\", 5)\n",
    "C0=colors[0]\n",
    "C1=colors[1]\n",
    "C2=colors[2]\n",
    "C3=colors[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "palette= {\n",
    "    'basset': C3, 'beetle': C1, 'bloodhound': C3, 'bluejay': C0,\n",
    "    'bluesedan': C1, 'bluesport': C1, 'brown': C1, 'bullmastiff': C3,\n",
    "    'chihuahua': C3, 'crow': C0, 'cuckoo': C0, 'doberman': C3,\n",
    "    'goldenretriever': C3, 'hatchback': C1, 'inlay': C2, 'knob': C2,\n",
    "    'leather': C2, 'nightingale': C0, 'pigeon': C0, 'pug': C3,\n",
    "    'redantique': C1, 'redsport': C1, 'robin': C0, 'sling': C2,\n",
    "    'sparrow': C0, 'squat': C2, 'straight': C2, 'tomtit': C0,\n",
    "    'waiting': C2, 'weimaraner': C3, 'white': C1, 'woven': C2,\n",
    "}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "p = sns.pointplot(x=\"Condition\", hue=\"objects\", y= \"Mean Streak Length\",data=data,ci=95\\\n",
    "                  ,dodge= 0.2, palette = palette)\n",
    "p.set(ylim=(1, 3.5))\n",
    "plt.setp([p.get_children()[0],p.get_children()],alpha=0.4)\n",
    "\n",
    "leg_elements = [Line2D([0], [0], marker='o', color='w', label='bird',\n",
    "                          markerfacecolor=C0, markersize=15),\n",
    "                Line2D([0], [0], marker='o', color='w', label='car',\n",
    "                          markerfacecolor=C1, markersize=15),\n",
    "                Line2D([0], [0], marker='o', color='w', label='chair',\n",
    "                          markerfacecolor=C2, markersize=15),\n",
    "                Line2D([0], [0], marker='o', color='w', label='dog',\n",
    "                          markerfacecolor=C3, markersize=15),\n",
    "               ]\n",
    "\n",
    "plt.legend(handles= leg_elements, prop={'size': 35})\n",
    "plt.tick_params(labelsize=35)\n",
    "plt.xlabel('', fontsize=35)\n",
    "plt.ylabel('', fontsize=35)\n",
    "#plt.savefig(os.path.join(plot_dir,'streak_length_pp'),edgecolor='w',bbox_inches='tight',dpi=500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA=D\n",
    "_sketch_ids= DA.sketch_id.unique()\n",
    "_sketch_ids = [x for x in _sketch_ids if x not in donotpermute]\n",
    "z_scores_sub=dict((k, gt_streak_zscore[k]) for k in _sketch_ids)\n",
    "plt.figure()\n",
    "plt.title('Intact mean streak Z-score Distribution for all sketches')\n",
    "h=sns.distplot(z_scores_sub.values(),kde=False,hist=True,norm_hist=False)\n",
    "plt.close()\n",
    "print 'mean and CI for all objs', calculate_CI(z_scores_sub.values())\n",
    "\n",
    "##broken out by condition\n",
    "for this_cond in stroke_df.condition.unique():\n",
    "    DA=stroke_df[stroke_df['condition']==this_cond]\n",
    "    _sketch_ids= DA.sketch_id.unique()\n",
    "    _sketch_ids = [x for x in _sketch_ids if x not in donotpermute]\n",
    "    z_scores_sub=dict((k, gt_streak_zscore[k]) for k in _sketch_ids)\n",
    "    plt.figure()\n",
    "    plt.title('Intact mean streak Z-score Distribution for {}'.format(this_cond))\n",
    "    h=sns.distplot(z_scores_sub.values(),kde=False,hist=True,norm_hist=False)\n",
    "    plt.close()\n",
    "    print 'Intact and CI for {} condition'.format(this_cond), calculate_CI(z_scores_sub.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating feature vectors and normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is where we make a num unique labels * 2 X number of sketches vector \n",
    "\n",
    "feature_vec = np.zeros((len(stroke_df.sketch_id.unique()),len(valid_labels)*2), dtype=int)\n",
    "ind=0\n",
    "start_pos=0\n",
    "end_pos=0\n",
    "meta_list=[]\n",
    "cols = ['sketch_id','target','condition','category','outcome']\n",
    "\n",
    "for cat in unique_cats:\n",
    "  \n",
    "    DS= stroke_df[stroke_df['category']==cat]\n",
    "    unique_labels_in_cat=valid_labels_dict[cat]\n",
    "    unique_sketches_in_cat=DS['sketch_id'].unique()\n",
    "    start_pos = end_pos\n",
    "    end_pos+= len(unique_labels_in_cat)\n",
    "    print start_pos, end_pos\n",
    "    clear_output(wait=True)\n",
    "    Label_Vec = np.zeros((len(unique_sketches_in_cat),len(unique_labels_in_cat)*2), dtype=int)\n",
    "    arc_length_vec = np.zeros((len(unique_sketches_in_cat),len(valid_labels_dict[cat])), dtype=int)\n",
    "    for s,sketch in enumerate(unique_sketches_in_cat):\n",
    "        \n",
    "        label_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        arc_vec = np.zeros(len(unique_labels_in_cat),dtype=int)\n",
    "        DSA=DS[DS['sketch_id']==sketch]\n",
    "      \n",
    "        meta_list.append(pd.Series([DSA['sketch_id'].unique(),DSA['target'].unique(),DSA['condition'].unique(),DSA['category'].unique(),DSA['outcome'].unique()], index=cols))\n",
    "        label_list = DSA.label.values        \n",
    "        for label in label_list:\n",
    "            if label in unique_labels_in_cat:\n",
    "                label_ind = unique_labels_in_cat==label\n",
    "                label_vec[label_ind] += 1\n",
    "        for label in unique_labels_in_cat:\n",
    "            DSB=DSA[DSA['label']==label]\n",
    "            label_ind = unique_labels_in_cat==label\n",
    "            arc_vec[label_ind] = DSB['arc_length'].sum()\n",
    "            \n",
    "        \n",
    "        feature_vec[ind,start_pos:end_pos]=label_vec\n",
    "        feature_vec[ind,start_pos+len(valid_labels):end_pos+len(valid_labels)]=arc_vec\n",
    "        ind+=1\n",
    "meta_df = pd.DataFrame(meta_list, columns=cols)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Changing column values from np arrays to strings/boolean\n",
    "\n",
    "def arr_to_str(arr):\n",
    "    return (arr[0])\n",
    "meta_df['sketch_id']=meta_df['sketch_id'].apply(arr_to_str)\n",
    "meta_df['target']=meta_df['target'].apply(arr_to_str)\n",
    "meta_df['condition']=meta_df['condition'].apply(arr_to_str)\n",
    "meta_df['category']=meta_df['category'].apply(arr_to_str)\n",
    "meta_df['outcome']=meta_df['outcome'].apply(arr_to_str)\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df= pd.DataFrame(feature_vec, columns=[s + '_numstrokes' for s in valid_labels]+[s + '_total_arclength' for s in valid_labels])\n",
    "##creating a compressed version of the feature df with no duplicates for parts\n",
    "\n",
    "labs_numstrokes=[]\n",
    "labs_total_arclength=[]\n",
    "for lab in np.unique(valid_labels):\n",
    "    labs_numstrokes.append(lab +'_numstrokes')\n",
    "    labs_total_arclength.append(lab+'_total_arclength')\n",
    "feature_df_labs=labs_numstrokes+labs_total_arclength   \n",
    "feature_df_final= pd.DataFrame(columns=feature_df_labs)\n",
    "\n",
    "\n",
    "for this_lab in feature_df_labs:\n",
    "    duplicates=[col for col in feature_df if col.startswith(this_lab)]\n",
    "    feature_df_final[this_lab]= feature_df[duplicates].sum(axis=1)\n",
    "feature_df = feature_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check to make sure the df looks okay\n",
    "assert len(feature_df.columns)==len(np.unique(feature_df.columns))\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sanity check: make sure that the numstrokes and arclength features each add up to 1\n",
    "numstrokes_cols = [i for i in feature_df.columns if i.split('_')[-1]=='numstrokes']\n",
    "arclength_cols = [i for i in feature_df.columns if i.split('_')[-1]=='arclength']\n",
    "feat_cols = numstrokes_cols + arclength_cols\n",
    "if dataset=='rawcounts':\n",
    "    assert len(np.unique(feature_df[arclength_cols].sum(axis=1).round(10)))==1\n",
    "    assert len(np.unique(feature_df[numstrokes_cols].sum(axis=1).round(10)))==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize feature_df (apply whitening)? \n",
    "## Warning, this will make it so numstrokes and arclength features DO NOT add up to 1\n",
    "whitening = True\n",
    "if whitening:\n",
    "    feature_df = normalize(feature_df)\n",
    "    print 'Applied whitening to raw feature matrix.'\n",
    "else:\n",
    "    print 'Did not apply whitening to raw feature matrix.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate meta and features to enable easy subsetting of dataframe\n",
    "F = pd.concat((meta_df,feature_df),axis=1)\n",
    "\n",
    "## add category to F dataframe so we can subset on that later\n",
    "F['category'] = F['target'].apply(lambda x: OBJECT_TO_CATEGORY[x])\n",
    "\n",
    "\n",
    "# hacky way of guarding against accidentally over-writing F, have a copy here called F0\n",
    "F0 = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate by target and condition and take the mean across rows within each group\n",
    "F2 = F.groupby(['target','condition']).mean().reset_index()\n",
    "F2['category'] = F2['target'].apply(lambda x: OBJECT_TO_CATEGORY[x])\n",
    "## get ordered list of all objects\n",
    "obj_list = np.unique(F.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_obj_list = ordered_objs = get_ordered_objs_list_by_category(F2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Empirical matrix\n",
    "c_means=[]\n",
    "f_means=[]\n",
    "\n",
    "for this_obj in ordered_objs:\n",
    "    c_obj,f_obj,c_obj_list,f_obj_list = subset_dataframe_by_condition(F0,to_inspect='object', this_object=this_obj )\n",
    "    c_mean = np.array(c_obj.mean())\n",
    "    c_means.append(c_mean)\n",
    "    f_mean = np.array(f_obj.mean())\n",
    "    f_means.append(f_mean)\n",
    "    \n",
    "# c_means = np.apply_along_axis(softmax,1,np.vstack(c_means))  \n",
    "# f_means = np.apply_along_axis(softmax,1,np.vstack(f_means))  \n",
    "all_means = np.vstack((c_means,f_means))\n",
    "#dmat = pdist(all_sample_means, 'correlation')\n",
    "#dmat = squareform(dmat)\n",
    "dmat = np.corrcoef(all_means)\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "plt.figure(figsize(8,8))\n",
    "plt.matshow(dmat, cmap=plt.cm.Spectral,vmin=-1.,vmax=1.)\n",
    "plt.colorbar(fraction=0.045)\n",
    "#t = plt.xticks(range(len(ordered_objs)*2), close_far_labels, fontsize=10,rotation='vertical')\n",
    "#t = plt.yticks(range(len(ordered_objs)*2), close_far_labels, fontsize=10)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel('bird car chair dog bird car chair dog\\n  close                      far    ',\\\n",
    "          fontsize=25)\n",
    "plt.ylabel('    far                     close\\ndog chair car bird dog chair car bird',\\\n",
    "          fontsize=25)\n",
    "plt.tick_params(axis='x',bottom=False,top=False,labelbottom=False)\n",
    "plt.tick_params(axis='x',bottom=False,top=False,labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_close_dists = []\n",
    "mean_far_dists = []\n",
    "mean_within_dists = []\n",
    "mean_between_dists = []\n",
    "cf_mean_diff = []\n",
    "wb_mean_diff=[]\n",
    "num_iters = 10 #Temporary low sampling number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iters):\n",
    "    c_sample_means=[]\n",
    "    f_sample_means=[]\n",
    "\n",
    "    for this_obj in ordered_objs:\n",
    "        c_obj,f_obj,c_obj_list,f_obj_list = subset_dataframe_by_condition(F0,to_inspect='object', this_object=this_obj )\n",
    "        c_indices = np.random.choice(c_obj.shape[0],size=c_obj.shape[0],replace=True) #sample with replacement\n",
    "        c_sample = c_obj.iloc[c_indices]\n",
    "        c_sample.reset_index(drop=True)\n",
    "        f_indices= np.random.choice(f_obj.shape[0],size=f_obj.shape[0],replace=True) #sample with replacement\n",
    "        f_sample =f_obj.iloc[f_indices]\n",
    "        f_sample.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        c_mean = np.array(c_sample.mean())\n",
    "        c_sample_means.append(c_mean)\n",
    "        f_mean = np.array(f_sample.mean())\n",
    "        f_sample_means.append(f_mean)\n",
    "\n",
    "#     c_sample_means = np.apply_along_axis(softmax,1,np.vstack(c_sample_means))  \n",
    "#     f_sample_means = np.apply_along_axis(softmax,1,np.vstack(f_sample_means))  \n",
    "    c_sample_means = np.apply_along_axis(minmaxscale,1,np.vstack(c_sample_means))  \n",
    "    f_sample_means = np.apply_along_axis(minmaxscale,1,np.vstack(f_sample_means))  \n",
    "    all_sample_means = np.vstack((c_sample_means,f_sample_means))\n",
    "    #dmat = pdist(all_sample_means, 'correlation')\n",
    "    #dmat = squareform(dmat)\n",
    "    dmat = np.corrcoef(all_sample_means)\n",
    "    # plt.rcParams[\"axes.grid\"] = False\n",
    "    # plt.figure(figsize(8,8))\n",
    "    # plt.matshow(dmat, cmap=plt.cm.Spectral,vmin=-1.,vmax=1.)\n",
    "    # plt.colorbar(fraction=0.05)\n",
    "    # t = plt.xticks(range(len(ordered_objs)*2), close_far_labels, fontsize=10,rotation='vertical')\n",
    "    # t = plt.yticks(range(len(ordered_objs)*2), close_far_labels, fontsize=10)\n",
    "    # plt.tick_params(axis='x',bottom=False,top=False,labelbottom=False)\n",
    "\n",
    "    half_dim = int(dmat.shape[0]/2)\n",
    "    cf_dmat= dmat[:half_dim,half_dim:]\n",
    "    cc_dmat = dmat[:half_dim,:half_dim]\n",
    "    ff_dmat = dmat[half_dim:,half_dim:]\n",
    "\n",
    "    cat_dim = half_dim/4\n",
    "    close_dists = []\n",
    "    far_dists = []\n",
    "    within_dists = []\n",
    "    between_dists = []\n",
    "    for catnum in range(len(unique_cats)):\n",
    "        start_ind = int(cat_dim*catnum)\n",
    "        end_ind = int(cat_dim*(catnum+1))\n",
    "        f_cat_dmat = ff_dmat[start_ind:end_ind,start_ind:end_ind]\n",
    "        c_cat_dmat = cc_dmat[start_ind:end_ind,start_ind:end_ind]\n",
    "        cf_cat_dmat = cf_dmat[start_ind:end_ind,start_ind:end_ind]\n",
    "\n",
    "        triu_inds = np.triu_indices(cat_dim,k=1)\n",
    "        c_cat_dist = np.mean(c_cat_dmat[triu_inds])\n",
    "        f_cat_dist = np.mean(f_cat_dmat[triu_inds])\n",
    "        close_dists.append(c_cat_dist)\n",
    "        far_dists.append(f_cat_dist)\n",
    "        \n",
    "         \n",
    "        within_dists.append(np.mean(np.diag(cf_cat_dmat)))\n",
    "        od_inds = np.where(~np.eye(cf_cat_dmat.shape[0],dtype=bool))\n",
    "        between_dists.append(np.mean(cf_cat_dmat[od_inds]))\n",
    "        \n",
    "    mean_close_dists.append(np.mean(close_dists))\n",
    "    mean_far_dists.append(np.mean(far_dists))\n",
    "    cf_mean_diff.append(np.mean(far_dists)-np.mean(close_dists))\n",
    "    mean_within_dists.append(np.mean(within_dists))\n",
    "    mean_between_dists.append(np.mean(between_dists))\n",
    "    wb_mean_diff.append(np.mean(within_dists)-np.mean(between_dists))\n",
    "                            \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals = [np.array(mean_close_dists).mean(),np.array(mean_far_dists).mean()]\n",
    "spreadclose= np.percentile(mean_close_dists, 2.5),np.percentile(mean_close_dists, 97.5)\n",
    "spreadfar = np.percentile(mean_far_dists,2.5),np.percentile(mean_far_dists, 97.5)\n",
    "lower_err = np.array(mean_far_dists).mean()-spreadfar[0],np.array(mean_close_dists).mean()-spreadclose[0]\n",
    "upper_err = spreadfar[1]-np.array(mean_far_dists).mean(),spreadclose[1]-np.array(mean_close_dists).mean()\n",
    "\n",
    "errs= np.vstack((lower_err, upper_err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(2)\n",
    "fig = plt.figure(figsize=(4,8))\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette('tab20c')\n",
    "color_list = [colors[4],colors[6]]\n",
    "plt.bar(y_pos,y_vals, yerr=errs,  width= 0.8, capsize=0,color=color_list)\n",
    "plt.ylim((0.,1.))\n",
    "plt.xlim((-0.5,1.5))\n",
    "plt.ylabel('correlation')\n",
    "plt.xticks(y_pos,['close','far'])\n",
    "#plt.savefig(os.path.join(plot_dir,'close_far_dispersion.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreaddiff= np.percentile(cf_mean_diff,2.5),np.percentile(cf_mean_diff,97.5)\n",
    "lower_err = np.array(cf_mean_diff).mean()-spreaddiff[0]\n",
    "upper_err = spreaddiff[1]-np.array(cf_mean_diff).mean()\n",
    "differrs = np.vstack((lower_err, upper_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = 1\n",
    "fig = plt.figure(figsize=(2,8))\n",
    "plt.bar(y_pos,np.mean(cf_mean_diff), yerr= differrs, width= 0.5,capsize=0)\n",
    "plt.ylim((0,0.4))\n",
    "plt.xlim(0.5, 1.5)\n",
    "plt.xticks([])\n",
    "plt.ylabel('close-far difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadwithin= np.percentile(mean_within_dists, 2.5),np.percentile(mean_within_dists, 97.5)\n",
    "spreadbetween = np.percentile(mean_between_dists,2.5),np.percentile(mean_between_dists, 97.5)\n",
    "\n",
    "lower_err = np.array(mean_within_dists).mean()-spreadwithin[0],np.array(mean_between_dists).mean()-spreadbetween[0]\n",
    "upper_err = spreadwithin[1]-np.array(mean_within_dists).mean(),spreadbetween[1]-np.array(mean_between_dists).mean()\n",
    "\n",
    "errs= np.vstack((lower_err, upper_err))\n",
    "\n",
    "fig = plt.figure(figsize=(5,8))\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette('tab20c')\n",
    "color_list = [colors[4],colors[6]]\n",
    "y_vals = [np.array(mean_within_dists).mean(),np.array(mean_between_dists).mean()]\n",
    "print y_vals\n",
    "print errs\n",
    "y_pos = np.arange(2)\n",
    "plt.bar(y_pos,y_vals, yerr= errs,  width= 0.8, capsize=0,color=color_list)\n",
    "plt.ylim((0,1))\n",
    "plt.xlim((-0.5,1.5))\n",
    "plt.ylabel('correlation')\n",
    "plt.xticks(y_pos,['within \\nobject','between \\nobjects'])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(plot_dir,'within_object_btw_context_similarity.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreaddiff= np.percentile(wb_mean_diff,2.5),np.percentile(wb_mean_diff,97.5)\n",
    "lower_err = np.array(wb_mean_diff).mean()-spreaddiff[0]\n",
    "upper_err = spreaddiff[1]-np.array(wb_mean_diff).mean()\n",
    "differrs = np.vstack((lower_err, upper_err))\n",
    "\n",
    "y_pos = 1\n",
    "plt.bar(y_pos,np.mean(wb_mean_diff), yerr= differrs, width= 0.5,capsize=20)\n",
    "plt.ylim((0,0.5))\n",
    "plt.xlim(0, 2)\n",
    "plt.xticks([])\n",
    "plt.ylabel('Within-between difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get empirical sparsity difference for close and far\n",
    "##Get close and far vectors:\n",
    "co,fa,obc,obf = subset_dataframe_by_condition(F2,to_inspect='all')\n",
    "cs = [] #close sparsity\n",
    "fs = [] #far sparsity\n",
    "\n",
    "cs = co.apply(get_sparsity, axis = 1)\n",
    "fs = fa.apply(get_sparsity, axis = 1)\n",
    "\n",
    "print 'difference in sparsity between close and far = {}'.format(np.mean(cs.values) -  np.mean(fs.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "close  0.3460397682282061              far  0.2769144895890592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bootstrap resample to get 95% CIs \n",
    "nIter = 5000\n",
    "sdiff=[]\n",
    "for currIter in np.arange(nIter):\n",
    "    print 'Running bootstrap iteration {} of {}'.format(currIter+1,nIter)\n",
    "    clear_output(wait=True)\n",
    "    Fboot = resample_sketches(F0,random_state=currIter)\n",
    "    F2boot = aggregate_sketches(Fboot,OBJECT_TO_CATEGORY=OBJECT_TO_CATEGORY)\n",
    "    c_boot,f_boot,obc,obf = subset_dataframe_by_condition(F2boot,to_inspect='all')\n",
    "       \n",
    "    csboot = c_boot.apply(get_sparsity,axis=1)\n",
    "    fsboot = f_boot.apply(get_sparsity,axis=1)\n",
    "    sdiff.append(np.mean(csboot.values)-np.mean(fsboot.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.mean(sdiff),np.percentile(sdiff,2.5), np.percentile(sdiff,97.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdiffdf = pd.DataFrame(sdiff)\n",
    "sdiffdf.columns=['sparsity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette('tab20c')\n",
    "sns.set_context('poster')\n",
    "fig = plt.figure(figsize=(4,8))\n",
    "mu = np.mean(sdiff)\n",
    "lb = np.percentile(sdiff,2.5)\n",
    "ub = np.percentile(sdiff,97.5)\n",
    "plt.bar(0,mu,color=colors[4],width=0.3)\n",
    "plt.errorbar(0,mu,\n",
    "             yerr=np.vstack((mu-lb,ub-mu)),\n",
    "             color='black',elinewidth=3)\n",
    "wid = 0.3\n",
    "plt.xlim(-wid,wid)\n",
    "plt.ylim(0,1.)\n",
    "plt.ylabel('vector sparsity difference',fontsize=22)\n",
    "plt.xlabel(' ')\n",
    "plt.xticks([])\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(plot_dir,'difference_vector_sparsity.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sdiff).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print lb,ub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA and visualize MDS plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate by target and condition and take the mean across rows within each group\n",
    "F2 = F.groupby(['target','condition']).mean().reset_index()\n",
    "\n",
    "## re-add category back to the F dataframe so we can subset on that later \n",
    "##( taking mean above removes it b/c it is a string)\n",
    "F2['category'] = F2['target'].apply(lambda x: OBJECT_TO_CATEGORY[x])\n",
    "\n",
    "## sort into standard order\n",
    "F2 = F2.sort_values(['condition','category','target']).reset_index(drop=True)\n",
    "\n",
    "## extract just the feature columns and store as np array\n",
    "PF = np.array(F2[feat_cols])\n",
    "## do the same for the meta\n",
    "PM = F2.loc[:,['condition','category','target']]\n",
    "\n",
    "# optionally apply PCA\n",
    "apply_pca = True\n",
    "num_pcs = 3\n",
    "if apply_pca:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=num_pcs)\n",
    "    pca.fit(PF)\n",
    "    print('Applying PCA and transforming data, using {} components'.format(num_pcs))\n",
    "    PF = pca.fit_transform(PF)\n",
    "\n",
    "PF = pd.DataFrame(PF)    \n",
    "\n",
    "## join into single dataframe for plotting\n",
    "P = pd.concat([PF,PM],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "colors = sns.color_palette(\"husl\", 5)\n",
    "sns.scatterplot(data=P,\n",
    "                x=0,\n",
    "                y=1,\n",
    "                hue='category',\n",
    "                style='condition',\n",
    "                palette=colors[:4])\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(' ')\n",
    "axlim =  7\n",
    "plt.xlim(-axlim,axlim)\n",
    "# plt.xticks(np.arange(-axlim,axlim), 1.)\n",
    "plt.ylim(-axlim,axlim)\n",
    "plt.legend(bbox_to_anchor=(1.,1.))\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(os.path.join(plot_dir,'MDS_part_vectors.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
